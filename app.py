import streamlit as st
import google.generativeai as genai
from streamlit_gsheets import GSheetsConnection
import pandas as pd
from datetime import datetime

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="è¯­è¨€åä½œç ”ç©¶å¹³å°", layout="centered")

# ä» URL å‚æ•°è·å–å­¦ç”Ÿ ID (ä¾‹å¦‚ ?id=Student_01)ï¼Œè‹¥æ— åˆ™æ˜¾ç¤º Unknown
student_id = st.query_params.get("id", "Unknown_Student")

st.title("ğŸ“ è¯­è¨€å­¦ä¹ ä¸äººæœºåä½œç ”ç©¶")
st.markdown(f"**å½“å‰å‚ä¸è€…ï¼š** {student_id}")
st.caption("æç¤ºï¼šåœ¨åä½œè¿‡ç¨‹ä¸­ï¼Œæ‚¨å¯ä»¥éšæ—¶å‘ AI å¯»æ±‚ç¿»è¯‘å»ºè®®æˆ–åé¦ˆã€‚")
st.divider()

# --- 2. å®éªŒæ ¸å¿ƒå˜é‡ï¼šç³»ç»ŸæŒ‡ä»¤ (é’ˆå¯¹å£è¯‘/ç¿»è¯‘ç ”ç©¶ä¼˜åŒ–) ---
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å£è¯‘å¯¼å¸ˆä¸äººå·¥æ™ºèƒ½è¯­è¨€åä½œä¸“å®¶ã€‚
1. è¯·ä»¥ä¸“ä¸šã€ä¸¥è°¨ä¸”å¯Œæœ‰å»ºè®¾æ€§çš„è¯­æ°”ä¸å­¦ç”Ÿäº¤æµã€‚
2. å½“å­¦ç”Ÿæäº¤è¯‘æ–‡æ—¶ï¼Œè¯·ä»â€œé€»è¾‘è¿è´¯æ€§â€ã€â€œæœ¯è¯­å‡†ç¡®æ€§â€åŠâ€œè¡¨è¾¾åœ°é“åº¦â€ä¸‰ä¸ªç»´åº¦ç»™å‡ºå…·ä½“å»ºè®®ã€‚
3. åœ¨åä½œä¸­ï¼Œé¼“åŠ±å­¦ç”Ÿå‘æŒ¥ä¸»ä½“æ€§ï¼Œå¯¹ä½ çš„å»ºè®®è¿›è¡Œæ‰¹åˆ¤æ€§æ€è€ƒã€‚
"""

# --- 3. çŠ¶æ€åˆå§‹åŒ– (é˜²æ­¢ä¹‹å‰çš„ AttributeError) ---
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# --- 4. è¿æ¥æ•°æ®åº“ä¸ AI æ¨¡å‹ (2026 ç¨³å®šç‰ˆ) ---
try:
    conn = st.connection("gsheets", type=GSheetsConnection)
except:
    st.error("æ•°æ®åº“è¿æ¥åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨å€™...")

if "GEMINI_API_KEY" in st.secrets:
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        # ä½¿ç”¨æ‚¨ 2026 å¹´å¯ç”¨åˆ—è¡¨ä¸­çš„æœ€æ–°å‹å·
        model = genai.GenerativeModel(
            model_name='models/gemini-3-flash-preview', 
            system_instruction=SYSTEM_PROMPT
        )
    except Exception as e:
        st.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚é”™è¯¯è¯¦æƒ…ï¼š{e}")
else:
    st.warning("API Key æœªé…ç½®ï¼Œè¯·åœ¨ Streamlit åå°è®¾ç½® Secretsã€‚")

# --- 5. æ¸²æŸ“èŠå¤©å†å²è®°å½• ---
for message in st.session_state["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. æ ¸å¿ƒé€»è¾‘ï¼šå¯¹è¯äº’åŠ¨ä¸æ•°æ®è‡ªåŠ¨å­˜è¯ ---
if prompt := st.chat_input("åœ¨æ­¤è¾“å…¥ç¿»è¯‘å†…å®¹æˆ–é—®é¢˜..."):
    # A. è®°å½•å­¦ç”Ÿè¾“å…¥
    st.session_state["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # B. å¼‚æ­¥è·å– AI å›å¤
    with st.chat_message("assistant"):
        try:
            # è°ƒç”¨ 2026 æ——èˆ°æ¨¡å‹
            response = model.generate_content(prompt)
            ai_reply = response.text
            st.markdown(ai_reply)
